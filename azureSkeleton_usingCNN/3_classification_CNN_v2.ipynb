{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils CNN 객체 생성 -- Initialize\n",
      " Current workaing path [root] d:\\바탕화면\\Conda_WS\\tug_pjt\\own\\azureSkeleton_usingCNN\n",
      " Current workaing path [dataset]  D:\\바탕화면\\2020_tug_walkcam_dataset\\TUG_dataset\\arrangedData_LabelSave\n",
      "Folder index: 0 ,    Folder name: 2020_11_03_(result) \n",
      "     ----------------------------------------------------------------------         \n",
      "     Subject Idx: 0,      Subject: bys_tug ,   # fo csvFiles: 9\n",
      "     ----------------------------------------------------------------------         \n",
      "     Subject Idx: 1,      Subject: cbd_tug ,   # fo csvFiles: 10\n",
      "     ----------------------------------------------------------------------         \n",
      "     Subject Idx: 2,      Subject: cyj_tug ,   # fo csvFiles: 10\n",
      "Folder index: 1 ,    Folder name: 2020_11_20_v1_(result) \n",
      "     ----------------------------------------------------------------------         \n",
      "     Subject Idx: 3,      Subject: NHJ_60 ,   # fo csvFiles: 9\n",
      "     ----------------------------------------------------------------------         \n",
      "     Subject Idx: 4,      Subject: kw ,   # fo csvFiles: 10\n",
      "     ----------------------------------------------------------------------         \n",
      "     Subject Idx: 5,      Subject: kyh ,   # fo csvFiles: 10\n",
      "     ----------------------------------------------------------------------         \n",
      "     Subject Idx: 6,      Subject: lhs ,   # fo csvFiles: 10\n",
      "     ----------------------------------------------------------------------         \n",
      "     Subject Idx: 7,      Subject: nhs ,   # fo csvFiles: 10\n",
      "     ----------------------------------------------------------------------         \n",
      "     Subject Idx: 8,      Subject: pjh ,   # fo csvFiles: 10\n",
      "     ----------------------------------------------------------------------         \n",
      "     Subject Idx: 9,      Subject: pss ,   # fo csvFiles: 10\n",
      "     ----------------------------------------------------------------------         \n",
      "     Subject Idx: 10,      Subject: rjh ,   # fo csvFiles: 11\n",
      "     ----------------------------------------------------------------------         \n",
      "     Subject Idx: 11,      Subject: yjh ,   # fo csvFiles: 10\n",
      "Folder index: 2 ,    Folder name: 2020_11_20_v2_(result) \n",
      "     ----------------------------------------------------------------------         \n",
      "     Subject Idx: 12,      Subject: bys ,   # fo csvFiles: 9\n",
      "     ----------------------------------------------------------------------         \n",
      "     Subject Idx: 13,      Subject: cbd ,   # fo csvFiles: 10\n",
      "     ----------------------------------------------------------------------         \n",
      "     Subject Idx: 14,      Subject: cyj ,   # fo csvFiles: 10\n",
      "     ----------------------------------------------------------------------         \n",
      "     Subject Idx: 15,      Subject: cyj2 ,   # fo csvFiles: 10\n",
      "     ----------------------------------------------------------------------         \n",
      "     Subject Idx: 16,      Subject: jdh ,   # fo csvFiles: 10\n",
      "     ----------------------------------------------------------------------         \n",
      "     Subject Idx: 17,      Subject: jek ,   # fo csvFiles: 10\n",
      "     ----------------------------------------------------------------------         \n",
      "     Subject Idx: 18,      Subject: kch ,   # fo csvFiles: 10\n",
      "-----> [ Total Trials] (# of Trial):  189\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.utils_CNN_v2 import utilsCNN\n",
    "from Visualization.plot_graph import plot_graph\n",
    "\n",
    "utilsCNN = utilsCNN()\n",
    "plots = plot_graph()\n",
    "\n",
    "# %matplotlib tk\n",
    "np.random.seed(7)\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "labelData_dataDir = 'D:/바탕화면/2020_tug_walkcam_dataset/TUG_dataset/arrangedData_LabelSave' ; \n",
    "print(\" Current workaing path [root]\", os.getcwd())  \n",
    "datasetDir =  labelData_dataDir\n",
    "os.chdir(datasetDir) ; print(\" Current workaing path [dataset] \", os.getcwd())  # -- Dataset 있는 곳으로 경로 변경 \n",
    "\n",
    "# -------- 1. get csv file list for every trial \n",
    "utilsCNN.getDatalist_forEveryTrials(ROOT_DIR = datasetDir, displayList=True)\n",
    "\n",
    "# # # ------ 2. getRawPelvis from All Trial (draw and save figures)\n",
    "utilsCNN.getData_forEveryTrial(ROOT_DIR = datasetDir, displayResult = False)  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set(x,y): (50828, 4) , (50828, 5) , Test Set(x,y): (23438, 4) , (23438, 5)\n"
     ]
    }
   ],
   "source": [
    "numFeature = 4 # timestamp_sec, pelvis_x, pelvis_y, pelvis_z\n",
    "numActions = 5  # \"sitting\": 0, \"sit-stand\":1, \"walking\":2, \"turning\":3, \"stand-sit\":4\n",
    "action_label_code = {\"sitting\": 0, \"sit-stand\":1, \"walking\":2, \"turning\":3, \"stand-sit\":4} \n",
    "\n",
    "train_x , train_y , test_x, test_y= utilsCNN.createDataset_fromCSV(ROOT_DIR=datasetDir, numFeature=numFeature, numActions = numActions, trainSubNum = 13, displayInfo=False)\n",
    "print(\"Train Set(x,y): {0} , {1} , Test Set(x,y): {2} , {3}\".format(train_x.shape,train_y.shape, test_x.shape, test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Sectioning Training and Test datasets: shape of each section will be: ( 4 x 15 )\n",
      "Training Data has been standardized:\n",
      " the mean is =  1210.874425609768  ; and the std is =  451.5064356237748\n",
      "number of sections:  16938\n",
      "[-1.6878 -1.6795 -1.6713 -1.659  -1.6508 -1.6426 -1.6344 -1.6262 -1.618\n",
      " -1.6098 -1.6016 -1.5934 -1.5852 -1.577  -1.5687]\n",
      "Test Data has been standardized:\n",
      "number of sections:  7808\n",
      "[-1.6878 -1.6798 -1.6672 -1.6593 -1.6511 -1.6429 -1.6347 -1.6265 -1.6177\n",
      " -1.61   -1.6016 -1.5936 -1.5852 -1.5772 -1.5649]\n",
      "---> Training Section: (13298, 4, 15) , Test Sections: (6161, 4, 15)\n"
     ]
    }
   ],
   "source": [
    "sliding_window_size = 15 # 30.. 1sec.. 50 Equals to 1 sec for MotionSense Dataset (it is on 50Hz samplig rate)\n",
    "step_size_of_sliding_window = 3 #10 \n",
    "print(\"--> Sectioning Training and Test datasets: shape of each section will be: (\",numFeature,\"x\",sliding_window_size,\")\")\n",
    "train_data, act_train_labels, train_mean, train_std = utilsCNN.time_series_2d_to_3d_section(train_x.copy(),train_y.copy(), numActions, sliding_window_size,step_size_of_sliding_window,standardize = True)\n",
    "\n",
    "test_data, act_test_labels, test_mean, test_std = utilsCNN.time_series_2d_to_3d_section(test_x.copy(), test_y.copy(), \n",
    "                                                                                          numActions,\n",
    "                                                                                          sliding_window_size,\n",
    "                                                                                          step_size_of_sliding_window,\n",
    "                                                                                          standardize = True,\n",
    "                                                                                          mean = train_mean, \n",
    "                                                                                          std = train_std)\n",
    "\n",
    "print(\"---> Training Section: {0} , Test Sections: {1}\".format(train_data.shape, test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Training Section: (13298, 4, 15, 1) , Test Sections: (6161, 4, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\n",
    "#from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.layers import Conv2D , MaxPooling2D, Dropout\n",
    "\n",
    "## Here we add an extra dimension to the datasets just to be ready for using with Convolution2D\n",
    "train_data = np.expand_dims(train_data, axis=3)\n",
    "test_data = np.expand_dims(test_data, axis=3)\n",
    "print(\"---> Training Section: {0} , Test Sections: {1}\".format(train_data.shape, test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train, height, width, channel = train_data.shape  #   (61728, 4, 50, 1) =  (number_of_secs , size_features , sliding_window_size, 1)\n",
    "metrics = ['acc']\n",
    "\n",
    "## MTCNN\n",
    "drop_prob_1 = 0.2 \n",
    "drop_prob_2 = 0.4 \n",
    "\n",
    "\n",
    "## Action model \n",
    "action_layer_dim = numActions # 4  # dws, ups, wlk, jog # , sit,  std \n",
    "action_activation_func = 'softmax'\n",
    "action_loss_func = 'categorical_crossentropy'\n",
    "\n",
    "\n",
    "# feature 가 row 에 하나씩 있음 -> kernel, pooling  시 (1, k) 로 수행 \n",
    "def activityModel():\n",
    "\n",
    "    input_layer = Input(shape = (height, width, 1) ) # (4, 50, 1) = (feature, sliding_window, 1)\n",
    "\n",
    "      # 50\n",
    "    conv_0 = Conv2D(15, kernel_size=(1, 5), strides=(1, 1), padding='valid', activation='relu') (input_layer) #5\n",
    "    conv_1 = Conv2D(15, kernel_size=(1, 5), strides=(1, 1), padding='same', activation='relu') (conv_0)\n",
    "    dense_1 = Dense(50, activation='relu') (conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size=(1,2)) (dense_1)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "\n",
    "      # 40\n",
    "    conv_2 = Conv2D(11, kernel_size=(1, 3), strides=(1, 1), padding='valid', activation='relu') (drop_1)# 5\n",
    "    dense_2 = Dense(40, activation='relu') (conv_2)\n",
    "    pool_2 = MaxPooling2D(pool_size=(1, 3)) (dense_2)  \n",
    "    drop_2 = Dropout(drop_prob_1) (pool_2)\n",
    "      # 20\n",
    "    conv_3 = Conv2D(10, kernel_size=(1, 3), strides=(1, 1), padding='same', activation='relu') (drop_2)\n",
    "    drop_3 = Dropout(drop_prob_1)(conv_3)\n",
    "\n",
    "    #------------------------------------ from now on...use drop_prob_2 \n",
    "    flat = Flatten() (drop_3)\n",
    "    hidden = Dense(400, activation = 'relu') (flat)\n",
    "    drop_4 = Dropout(drop_prob_2)(hidden)\n",
    "\n",
    "    #----------- Multi Task Output \n",
    "    action_out = Dense(action_layer_dim, activation = action_activation_func, name = 'ACTION') (drop_4)\n",
    "    \n",
    "    # --------- Model input/ Output Definition\n",
    "    activity_model = Model(inputs=input_layer, outputs = action_out)\n",
    "    activity_model.summary()\n",
    "\n",
    "    activity_model.compile(loss=action_loss_func, \n",
    "          optimizer=keras.optimizers.Adam(0.001),\n",
    "          metrics=metrics)\n",
    "\n",
    "    return activity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4, 15, 1)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 4, 11, 15)         90        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 4, 11, 15)         1140      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4, 11, 50)         800       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 3, 11)          1661      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4, 3, 40)          480       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 1, 40)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 1, 40)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 1, 10)          1210      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 1, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 400)               16400     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "ACTION (Dense)               (None, 5)                 2005      \n",
      "=================================================================\n",
      "Total params: 23,786\n",
      "Trainable params: 23,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "208/208 [==============================] - 1s 5ms/step - loss: 0.5615 - acc: 0.7623\n",
      "Epoch 2/5\n",
      "208/208 [==============================] - 1s 5ms/step - loss: 0.3120 - acc: 0.8474\n",
      "Epoch 3/5\n",
      "208/208 [==============================] - 1s 5ms/step - loss: 0.2591 - acc: 0.8769\n",
      "Epoch 4/5\n",
      "208/208 [==============================] - 1s 5ms/step - loss: 0.2154 - acc: 0.8976\n",
      "Epoch 5/5\n",
      "208/208 [==============================] - 1s 5ms/step - loss: 0.1941 - acc: 0.9083\n"
     ]
    }
   ],
   "source": [
    "## Training Phase\n",
    "batch_size = 64\n",
    "num_of_epochs = 5 #30\n",
    "verbosity = 1\n",
    "\n",
    "# Model Training \n",
    "model = activityModel()\n",
    "history = model.fit(train_data, act_train_labels,                \n",
    "              batch_size = batch_size,\n",
    "              epochs = num_of_epochs,\n",
    "              verbose = verbosity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 0s 1ms/step - loss: 0.1766 - acc: 0.9063\n",
      "--> Evaluation on Test Dataset:\n",
      "**** Accuracy for Activity Recognition task is:  [0.17662864923477173, 0.9063463807106018]\n"
     ]
    }
   ],
   "source": [
    "#------------- Evaluation \n",
    "\n",
    "results_1 = model.evaluate(test_data, act_test_labels,\n",
    "                                 verbose = verbosity)\n",
    "\n",
    "print(\"--> Evaluation on Test Dataset:\")\n",
    "print(\"**** Accuracy for Activity Recognition task is: \", results_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 4 4 4]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "(6161, 5)\n",
      "[0.7 0.7 0.7 ... 0.  0.  0. ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_predict = model.predict(test_data)\n",
    "\n",
    "y_pred_int = np.round(y_predict,1)\n",
    "print(y_predict.argmax(axis=1)) \n",
    "print(test_y[y_predict.argmax(axis=1)])\n",
    "# print(y_predict.shape) # (6161, 5)  , sliding window size \n",
    "\n",
    "y_pred_max = y_predict.argmax(axis=1)\n",
    "y_pred = y_pred_int[0][y_pred_max]\n",
    "print(y_pred)\n",
    "# x = np.arange(len(y_predict))\n",
    "\n",
    "# fig, ax = plt.subplots(nrows=5, ncols=1, figsize=(20, 10))\n",
    "# ax[0].plot(x, y_predict[:,0], 'g*', lw=0.1, label='sitting')\n",
    "# ax[1].plot(x, y_predict[:,1], 'b*', lw=0.1, label='sitStand')\n",
    "# ax[2].plot(x, y_predict[:,2], 'r*', lw=0.1, label='walking')\n",
    "# ax[3].plot(x, y_predict[:,3], 'g*', lw=0.1, label='Turning')\n",
    "# ax[4].plot(x, y_predict[:,4], 'b*', lw=0.1, label='standSit')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-5cecd8630d9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     plt.title(\"Predicted:{}\\nTrue:{}\".format(activity_types[y_pred[cor]-1], \n\u001b[0;32m      8\u001b[0m                                               activity_types[y_test[cor]-1]))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "y_pred = test_y[y_predict.argmax(axis=1)]\n",
    "y_test =np.argmax(test_y,axis=1)\n",
    "\n",
    "correct = np.nonzero(y_pred == y_test)\n",
    "incorrect = np.nonzero(y_pred != y_test)\n",
    "print(\"correct: \", correct)\n",
    "\n",
    "### Check the correctly-predicted samples\n",
    "plt.figure(1)\n",
    "for i, cor in enumerate(correct[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.subplots_adjust(hspace=1.0,wspace=1.0)\n",
    "    plt.plot(test_x.iloc[cor,:])\n",
    "    plt.title(\"Predicted:{}\\nTrue:{}\".format(activity_types[y_pred[cor]-1], \n",
    "                                              activity_types[y_test[cor]-1]))\n",
    "    plt.xticks([]) # turn off x labels\n",
    "    plt.yticks([])  # turn off y labels\n",
    "    #plt.tight_layout()\n",
    "plt.show()\n",
    "### Check the incorrectly-predicted samples\n",
    "plt.figure(2)\n",
    "for i, cor in enumerate(incorrect[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.subplots_adjust(hspace=1.0,wspace=1.0)\n",
    "    plt.plot(test_x.iloc[cor,:])\n",
    "    plt.title(\"Predicted:{}\\nTrue:{}\".format(activity_types[y_pred[cor]-1], \n",
    "                                              activity_types[y_test[cor]-1]))\n",
    "    plt.xticks([]) # turn off x labels\n",
    "    plt.yticks([])  # turn off y labels\n",
    "    #plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Confusion matrix (predictive performance on different classes)\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    function provided by sklearn example\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(cnf_matrix, classes=activity_types,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
