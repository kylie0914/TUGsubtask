{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prev workaing path [root] /home/sang/dataset/TUG/arrangedData_LabelSave\n",
      " Current workaing path [dataset]  /home/sang/dataset/TUG/arrangedData_LabelSave\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/client/session.py:1751: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "np.random.seed(7)\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "datasetDir = '/home/sang/dataset/TUG/arrangedData_LabelSave' ; print(\" Prev workaing path [root]\", os.getcwd())  \n",
    "os.chdir(datasetDir) ; print(\" Current workaing path [dataset] \", os.getcwd())  # -- Dataset 있는 곳으로 경로 변경 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[K-fold]  [(1, 2, 3), (1, 2, 4), (1, 2, 5), (1, 3, 4), (1, 3, 5), (1, 4, 5), (2, 3, 4), (2, 3, 5), (2, 4, 5), (3, 4, 5)]\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4,5]\n",
    "c = list(combinations(a, 3))\n",
    "print(\"[K-fold] \", c )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['JDW_tug'], ['JDW_tug_fixed'], ['cbd_tug', 'bys_tug', 'cyj_tug'], ['cbd', 'cyj2', 'cyj', 'bys', 'jdh', 'jek', 'kch'], ['kw', 'nhs', 'rjh', 'lhs', 'pjh', 'yjh', 'NHJ_60', 'kyh', 'pss']]\n",
      "----> Train subjects: 15 명, ['JDW_tug', 'JDW_tug_fixed', 'cbd_tug', 'bys_tug', 'cyj_tug', 'cbd', 'cyj2', 'cyj', 'bys', 'jdh', 'jek', 'kch', 'kw', 'nhs', 'rjh'] \n",
      "----> Test subjects: 6 명, ['lhs', 'pjh', 'yjh', 'NHJ_60', 'kyh', 'pss']\n"
     ]
    }
   ],
   "source": [
    "def trainData_split(datasetDir,ratio = 0.7, displayResult= True, shuffle =False,  train_Kfold = False):      \n",
    "    expDates = next(os.walk(datasetDir))[1]  # ['2020_11_03_(result)', '2020_11_20_v1_(result)', '2020_11_20_v2_(result)']\n",
    "    subjects = []\n",
    "    for dateFolder in expDates:\n",
    "        dateDir = os.path.join(datasetDir, dateFolder) \n",
    "        dataTypeDir = os.path.join(dateDir, \"Labeled_CSV\")\n",
    "        date_subjects = (next(os.walk(dataTypeDir))[1])\n",
    "        subjects.append(date_subjects)\n",
    "    print(subjects)\n",
    "\n",
    "    # 2D -> 1D [[sub1, sub2], [sub3, sub4]] -> [sub1, sub2, sub3, sub4]\n",
    "    total_subjects = []\n",
    "    for i in subjects:\n",
    "        total_subjects+=i\n",
    "    if shuffle:\n",
    "        random.shuffle(total_subjects)\n",
    "        \n",
    "    trainIdx = np.round((len(total_subjects)*ratio),0).astype(int)\n",
    "    train_subjects = total_subjects[:trainIdx]\n",
    "    test_subjects = total_subjects[trainIdx:]\n",
    "    if displayResult:\n",
    "        print(\"----> Train subjects: {0} 명, {1} \\n----> Test subjects: {2} 명, {3}\".format(len(train_subjects), train_subjects, len(test_subjects), test_subjects ))\n",
    "        \n",
    "    if train_Kfold:\n",
    "        train_subFold = list(combinations(train_subjects, 3))\n",
    "        print(\"[K-fold] \", train_subFold )\n",
    "        return train_subFold, test_subjectsS\n",
    "    else:\n",
    "        return train_subjects, test_subjects\n",
    "\n",
    "train_subjects, test_subjects = trainData_split(datasetDir,ratio = 0.7,shuffle = False, train_Kfold = False)    \n",
    "train_subjects =  ['NHJ_60',  'yjh', 'kyh', 'pss' ,'cyj_tug', 'cbd', 'cyj2', 'bys', 'jdh', 'jek', 'kch', 'kw', 'nhs', 'rjh'] \n",
    "normal_subjects = ['lhs', 'pjh', 'cbd_tug', 'bys_tug','cyj','JDW_tug_fixed']\n",
    "patients_subjects = ['JDW_tug_fixed']\n",
    "\n",
    "\n",
    "test_subjects = patients_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Shape X , Y: (55982, 3) , (55982, 5) \n",
      " Test Shape X , Y: (1033, 3) , (1033, 5)\n"
     ]
    }
   ],
   "source": [
    "numFeature = 3\n",
    "numActions = 5\n",
    "\n",
    "def getPelvisData(csvFile):\n",
    "    rawData = np.loadtxt(csvFile, delimiter=\",\")\n",
    "    timestamp = rawData[:,0]\n",
    "    pelvis_x = rawData[:,1]\n",
    "    pelvis_y = rawData[:,2]\n",
    "    pelvis_z = rawData[:,3]\n",
    "    actionList = rawData[:,4:9]\n",
    "    return timestamp, pelvis_x, pelvis_y, pelvis_z, actionList\n",
    "\n",
    "def create_dataset(datasetDir, train_subjects, test_subjects, displayResult = True):\n",
    "    train_x = np.zeros((0, numFeature))\n",
    "    train_y = np.zeros((0, numActions))\n",
    "    test_x = np.zeros((0, numFeature))\n",
    "    test_y = np.zeros((0, numActions))    \n",
    "    \n",
    "#     trainSet = None\n",
    "#     testSet = None\n",
    "\n",
    "    expDates = next(os.walk(datasetDir))[1]  # ['2020_11_03_(result)', '2020_11_20_v1_(result)', '2020_11_20_v2_(result)']\n",
    "    for dateFolder in expDates:\n",
    "        dateDir = os.path.join(datasetDir, dateFolder) \n",
    "        dataTypeDir = os.path.join(dateDir, \"Labeled_CSV\")\n",
    "        subjects = next(os.walk(dataTypeDir))[1]\n",
    "        \n",
    "        for subjectName in subjects:\n",
    "            subjectDir = os.path.join(dataTypeDir, subjectName)\n",
    "            for csvFileName  in next(os.walk(subjectDir))[2]:  \n",
    "                csvFile = os.path.join(subjectDir, csvFileName) \n",
    "                timestamp, pelvis_x, pelvis_y, pelvis_z, actionList = getPelvisData(csvFile) \n",
    "\n",
    "                    # -------- bind \n",
    "    #                 pelvisData = np.array([timestamp, pelvis_x, pelvis_y, pelvis_z]).T   # (frameNum, 4)\n",
    "                pelvisData = np.array([pelvis_x, pelvis_y, pelvis_z]).T              # (frameNum, 3) \n",
    "                actionData = np.array(actionList)                                    # (frameNum, 5)\n",
    "                dataset = tf.data.Dataset.from_tensor_slices( (pelvisData.astype('float32'), actionData.astype('float32')) )\n",
    "                \n",
    "                if subjectName in train_subjects:\n",
    "                    train_x = np.append(train_x, pelvisData, axis = 0 )\n",
    "                    train_y = np.append(train_y, actionData, axis = 0 )\n",
    "#                     if trainSet == None:\n",
    "#                         trainSet = dataset\n",
    "#                     else:\n",
    "#                         trainSet = trainSet.concatenate(dataset)\n",
    "              \n",
    "                elif subjectName in test_subjects:                   \n",
    "                    test_x = np.append(test_x, pelvisData, axis = 0 )\n",
    "                    test_y = np.append(test_y, actionData, axis = 0 )\n",
    "#                     if testSet == None:\n",
    "#                         testSet = dataset\n",
    "#                     else:\n",
    "#                         testSet = testSet.concatenate(dataset)\n",
    "\n",
    "    if displayResult:\n",
    "        print(\" Train Shape X , Y: {0} , {1} \\n Test Shape X , Y: {2} , {3}\".format(train_x.shape, train_y.shape, test_x.shape, test_y.shape))\n",
    "    return train_x, train_y, test_x, test_y\n",
    "                              \n",
    "train_x, train_y, test_x, test_y = create_dataset(datasetDir, train_subjects, test_subjects, displayResult = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_to_section(data_x, data_y, numActions, sliding_window_size, step_size_of_sliding_window, standardize=False, **options):\n",
    "    data = data_x  # sensor data\n",
    "    act_labels = data_y  # action labels\n",
    "    mean = 0\n",
    "    std = 1\n",
    "    \n",
    "    trainSet = None\n",
    "    testSet = None\n",
    "    if standardize:\n",
    "            # As usual, normalize test dataset by training dataset's parameters\n",
    "        if options:\n",
    "            mean = options.get(\"mean\")\n",
    "            std = options.get(\"std\")\n",
    "                # \\n test mean: {0}, std: {1}\\n\\n\".format(mean,std))\n",
    "            print(\"Test Data has been standardized:\")\n",
    "        else:\n",
    "                # csv 한 줄의 mean ..이걸 모든 sensor data들에 대해 수행\n",
    "            mean = data.mean(axis=0)\n",
    "            std = data.std(axis=0)\n",
    "            print(\"Training Data has been standardized:\\n the mean is = \", str(mean.mean()), \" ; and the std is = \", str(std.mean()))\n",
    "            # mean removal and variance scaling\n",
    "        data -= mean\n",
    "        data /= std\n",
    "    else:\n",
    "        print(\"----> Without Standardization.....\")\n",
    "\n",
    "        # We want the Rows of matrices show each Feature and the Columns show time points.\n",
    "        # before transepose,,(145687, 12) -->  After (12, 145687)\n",
    "    data = data.T\n",
    "\n",
    "    size_features = data.shape[0]  # 4\n",
    "    size_data = data.shape[1]\n",
    "\n",
    "    number_of_secs = round( ((size_data - sliding_window_size)/step_size_of_sliding_window) )\n",
    "\n",
    "        # Create a 3D matrix for Storing Snapshots\n",
    "    secs_data = np.zeros((number_of_secs, size_features, sliding_window_size))\n",
    "    act_secs_labels = np.zeros((number_of_secs, numActions))\n",
    "    print(\"number of sections: \", number_of_secs, \"size of data\", size_data )\n",
    "    k = 0\n",
    "    for i in range(0, (size_data) - sliding_window_size, step_size_of_sliding_window):\n",
    "        j = i // step_size_of_sliding_window # 0, 3, 6, 12\n",
    "        if(j >= number_of_secs):\n",
    "            break\n",
    "\n",
    "        if(not (act_labels[i] == act_labels[i+sliding_window_size-1]).all()):\n",
    "            continue\n",
    "\n",
    "        secs_data[k] = data[0:size_features, i:i+sliding_window_size]\n",
    "        act_secs_labels[k] = act_labels[i].astype(int)\n",
    "        k = k+1\n",
    "    secs_data = secs_data[0:k]    \n",
    "    act_secs_labels = act_secs_labels[0:k]\n",
    "\n",
    "    return secs_data, act_secs_labels, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Sectioning Training and Test datasets: shape of each section will be: ( 3 x 15 )\n",
      "Training Data has been standardized:\n",
      " the mean is =  1643.6503128823158  ; and the std is =  610.8410907503521\n",
      "number of sections:  18656 size of data 55982\n",
      "Test Data has been standardized:\n",
      "number of sections:  339 size of data 1033\n",
      "\n",
      "\n",
      "---> Training X Section: (14743, 3, 15) , Training Label Section: (14743, 5) \n",
      "---> Test X Sections: (285, 3, 15) , Test Label Sections: (285, 5)\n"
     ]
    }
   ],
   "source": [
    "sliding_window_size = 15 # 30.. 1sec.. 50 Equals to 1 sec for MotionSense Dataset (it is on 50Hz samplig rate)\n",
    "step_size_of_sliding_window = 3 #10 \n",
    "print(\"--> Sectioning Training and Test datasets: shape of each section will be: (\", numFeature, \"x\", sliding_window_size, \")\")\n",
    "\n",
    "train_x_secs, train_y_secs, train_mean, train_std = time_series_to_section(train_x.copy(), train_y.copy(), numActions, sliding_window_size,step_size_of_sliding_window, standardize = True)\n",
    "\n",
    "test_x_secs, test_y_secs, test_mean, test_std = time_series_to_section(test_x.copy(), test_y.copy(), numActions, sliding_window_size, step_size_of_sliding_window, standardize = True, mean = train_mean, std = train_std)\n",
    "\n",
    "print(\"\\n\\n---> Training X Section: {0} , Training Label Section: {1} \\n---> Test X Sections: {2} , Test Label Sections: {3}\".format(train_x_secs.shape, train_y_secs.shape, test_x_secs.shape, test_y_secs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Training Section: (14743, 3, 15, 1) , Test Sections: (285, 3, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Conv2D , MaxPooling2D, Dropout\n",
    "\n",
    "## Here we add an extra dimension to the datasets just to be ready for using with Convolution2D\n",
    "train_x_block = np.expand_dims(train_x_secs, axis=3)\n",
    "test_x_block = np.expand_dims(test_x_secs, axis=3)\n",
    "print(\"---> Training Section: {0} , Test Sections: {1}\".format(train_x_block.shape, test_x_block.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train, height, width, channel = train_x_block.shape  #   (13298, 4, 15, 1) =  (number_of_secs , size_features , sliding_window_size, 1)\n",
    "metrics = ['acc']\n",
    "\n",
    "## MTCNN\n",
    "drop_prob_1 = 0.2 \n",
    "drop_prob_2 = 0.4 \n",
    "\n",
    "\n",
    "## Action model \n",
    "action_layer_dim = numActions # 4  # dws, ups, wlk, jog # , sit,  std \n",
    "action_activation_func = 'softmax'\n",
    "action_loss_func = 'categorical_crossentropy'\n",
    "\n",
    "\n",
    "def activityModel():\n",
    "    input_layer = Input(shape = (height, width, 1) ) # (4, 15, 1) = (feature, sliding_window, 1)\n",
    "\n",
    "    conv_0 = Conv2D(15, kernel_size=(1, 5), strides=(1, 1), padding='valid',  activation='relu') (input_layer) #5\n",
    "    conv_1 = Conv2D(15, kernel_size=(1, 5), strides=(1, 1), padding='same', activation='relu') (conv_0)\n",
    "    dense_1 = Dense(50, activation='relu') (conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size=(1,2)) (dense_1)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "\n",
    "\n",
    "    conv_2 = Conv2D(11, kernel_size=(1, 3), strides=(1, 1), padding='valid',  activation='relu') (drop_1)# 5\n",
    "    dense_2 = Dense(40, activation='relu') (conv_2)\n",
    "    pool_2 = MaxPooling2D(pool_size=(1, 3)) (dense_2)  \n",
    "    drop_2 = Dropout(drop_prob_1) (pool_2)\n",
    "\n",
    "    conv_3 = Conv2D(10, kernel_size=(1, 3), strides=(1, 1), padding='same',  activation='relu') (drop_2)\n",
    "    drop_3 = Dropout(drop_prob_1)(conv_3)\n",
    "\n",
    "    flat = Flatten() (drop_3)\n",
    "    hidden = Dense(400, activation = 'relu') (flat)\n",
    "    drop_4 = Dropout(drop_prob_2)(hidden)\n",
    "\n",
    "    action_out = Dense(action_layer_dim, activation = action_activation_func, name = 'ACTION') (drop_4)\n",
    "    \n",
    "    # --------- Model input/ Output Definition\n",
    "    activity_model = Model(inputs=input_layer, outputs = action_out)\n",
    "    activity_model.summary()\n",
    "\n",
    "    activity_model.compile(loss=action_loss_func, optimizer=keras.optimizers.Adam(0.001), metrics=metrics)\n",
    "\n",
    "    return activity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 3, 15, 1)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 3, 11, 15)         90        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 11, 15)         1140      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3, 11, 50)         800       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 3, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 11)          1661      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3, 3, 40)          480       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 1, 40)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 1, 40)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 1, 10)          1210      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 1, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 400)               12400     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "ACTION (Dense)               (None, 5)                 2005      \n",
      "=================================================================\n",
      "Total params: 19,786\n",
      "Trainable params: 19,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.6285 - acc: 0.7464\n",
      "Epoch 2/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.4129 - acc: 0.8236\n",
      "Epoch 3/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.3455 - acc: 0.8642\n",
      "Epoch 4/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.3055 - acc: 0.8871\n",
      "Epoch 5/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2766 - acc: 0.8974\n",
      "Epoch 6/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2694 - acc: 0.8997\n",
      "Epoch 7/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2620 - acc: 0.9035\n",
      "Epoch 8/30\n",
      "231/231 [==============================] - 1s 3ms/step - loss: 0.2553 - acc: 0.9059\n",
      "Epoch 9/30\n",
      "231/231 [==============================] - 1s 3ms/step - loss: 0.2553 - acc: 0.9051\n",
      "Epoch 10/30\n",
      "231/231 [==============================] - 1s 3ms/step - loss: 0.2487 - acc: 0.9092\n",
      "Epoch 11/30\n",
      "231/231 [==============================] - 1s 3ms/step - loss: 0.2434 - acc: 0.9095\n",
      "Epoch 12/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2371 - acc: 0.9114\n",
      "Epoch 13/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2443 - acc: 0.9086\n",
      "Epoch 14/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2307 - acc: 0.9123\n",
      "Epoch 15/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2407 - acc: 0.9093\n",
      "Epoch 16/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2332 - acc: 0.9135\n",
      "Epoch 17/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2280 - acc: 0.9151\n",
      "Epoch 18/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2322 - acc: 0.9140\n",
      "Epoch 19/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2282 - acc: 0.9151\n",
      "Epoch 20/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2307 - acc: 0.9158\n",
      "Epoch 21/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2248 - acc: 0.9157\n",
      "Epoch 22/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2240 - acc: 0.9155\n",
      "Epoch 23/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2293 - acc: 0.9153\n",
      "Epoch 24/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2248 - acc: 0.9170\n",
      "Epoch 25/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2231 - acc: 0.9177\n",
      "Epoch 26/30\n",
      "231/231 [==============================] - 1s 3ms/step - loss: 0.2222 - acc: 0.9187\n",
      "Epoch 27/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2206 - acc: 0.9175\n",
      "Epoch 28/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2193 - acc: 0.9200\n",
      "Epoch 29/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2227 - acc: 0.9160\n",
      "Epoch 30/30\n",
      "231/231 [==============================] - 1s 4ms/step - loss: 0.2228 - acc: 0.9172\n"
     ]
    }
   ],
   "source": [
    "## Training Phase\n",
    "batch_size = 64\n",
    "num_of_epochs = 30 # 35\n",
    "verbosity = 1\n",
    "\n",
    "# Model Training \n",
    "model = activityModel()\n",
    "history = model.fit(train_x_block, train_y_secs,                \n",
    "              batch_size = batch_size,\n",
    "              epochs = num_of_epochs,\n",
    "              verbose = verbosity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 4ms/step - loss: 1.9824 - acc: 0.6912\n",
      "--> Evaluation on Test Dataset:\n",
      "**** Accuracy for Activity Recognition task is:  [1.982426404953003, 0.6912280917167664]\n",
      " correct:  0.6912280701754386  [%] ,  incorrect:  0.3087719298245614  [%]\n"
     ]
    }
   ],
   "source": [
    "#------------- Evaluation \n",
    "results_1 = model.evaluate(test_x_block, test_y_secs, verbose = verbosity)\n",
    "print(\"--> Evaluation on Test Dataset:\")\n",
    "print(\"**** Accuracy for Activity Recognition task is: \", results_1)\n",
    "\n",
    "\n",
    "# ----------------- \n",
    "y_predict = model.predict(test_x_block) # (6161, 5)  \n",
    "y_pred_index = y_predict.argmax(axis=1) # print(y_pred_index) \n",
    "y_true_idx = np.argmax(test_y_secs, axis=1) # print(y_true_idx)\n",
    "\n",
    "correct = np.nonzero(y_true_idx == y_pred_index) # print(correct, len(correct[0]))\n",
    "incorrect = np.nonzero(y_true_idx != y_pred_index) # print(incorrect, len(incorrect[0]))\n",
    "\n",
    "valid_num = len(correct[0]) + len(incorrect[0])\n",
    "tot_num = len(y_true_idx)\n",
    "# print(\"[must same] # of real data: \", tot_num, \"==  # of pred data: \", valid_num)\n",
    "percent_correct = len(correct[0]) /tot_num\n",
    "percent_incorrect = len(incorrect[0])/tot_num\n",
    "print(\" correct: \", percent_correct,\" [%]\", \",  incorrect: \", percent_incorrect,\" [%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 4 4 4 4 4 4 4 4 4 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_true_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6072, 3, 15, 1) (6072, 5)\n",
      "(6072, 3, 15)\n",
      "6072\n"
     ]
    }
   ],
   "source": [
    "# def session_to_data(origin_x, origin_y, block_x, block_y, mode = 'test'):     # (# of train/test , # of features, slidingWindow, 1) (# of train/test, # of actions)\n",
    "#     sliding_window_size = 15\n",
    "#     step_size_of_sliding_window = 3\n",
    "#     print(block_x.shape, block_y.shape)\n",
    "#     print(block_x.reshape(-1,3,sliding_window_size).shape)  # (# of train/test , # of features, slidingWindow,) (# of train/test, # of actions)\n",
    "\n",
    "# #     23224\n",
    "#     data =[]\n",
    "#     section = block_x.shape[0]\n",
    "#     print(secsSize )\n",
    "#     for i in rnage(15):\n",
    "#         for j in range(3):\n",
    "#             section \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "            \n",
    "# #     print(np.array(data))\n",
    "# #     act_secs_labels = np.zeros((number_of_secs, 5))\n",
    "# #     print(\"number of sections: \", number_of_secs, \"size of data\", size_data )\n",
    "# #     k = 0\n",
    "# #     for i in range(0, (size_data) - sliding_window_size, step_size_of_sliding_window):\n",
    "# #         j = i // step_size_of_sliding_window # 0, 3, 6, 12\n",
    "# #         if(j >= number_of_secs):\n",
    "# #             break\n",
    "\n",
    "# #         if(not (act_labels[i] == act_labels[i+sliding_window_size-1]).all()):\n",
    "# #             continue\n",
    "\n",
    "# #         secs_data[k] = data[0:size_features, i:i+sliding_window_size]\n",
    "# #         act_secs_labels[k] = act_labels[i].astype(int)\n",
    "# #         k = k+1\n",
    "# #     secs_data = secs_data[0:k]    \n",
    "# #     act_secs_labels = act_secs_labels[0:k]\n",
    "# session_to_data(test_x, test_y, test_x_block, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 15, 1) for input Tensor(\"input_1:0\", shape=(None, 3, 15, 1), dtype=float32), but it was called on an input with incompatible shape (None, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py:717 call\n        return self._run_internal_graph(\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:885 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer conv2d is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: [None, 3]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0bda5b776032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (6161, 5)  , sliding window size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2772\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 2774\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2703\u001b[0m     self._function_cache.arg_relaxed_shapes[rank_only_cache_key] = (\n\u001b[1;32m   2704\u001b[0m         relaxed_arg_shapes)\n\u001b[0;32m-> 2705\u001b[0;31m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[1;32m   2706\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[1;32m   2707\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2657\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py:717 call\n        return self._run_internal_graph(\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:885 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /home/sang/miniconda3/envs/tug/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer conv2d is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: [None, 3]\n"
     ]
    }
   ],
   "source": [
    "# pelvis_y = 2\n",
    "# # for dataIdx in range(tot_num):\n",
    "# #     print(test_x_secs[:,2,:])\n",
    "    \n",
    "# fig, ax = plt.subplots(nrows=5, ncols=1, figsize=(20, 10))\n",
    "# ax[0].plot(test_x_secs[:,0,0], test_x_secs[:,2,0], 'g--', lw=0.1, label='sitting')\n",
    "# ax[1].plot(x, y_predict[:,1], 'b*', lw=0.1, label='sitStand')\n",
    "# ax[2].plot(x, y_predict[:,2], 'r*', lw=0.1, label='walking')\n",
    "# ax[3].plot(x, y_predict[:,3], 'g*', lw=0.1, label='Turning')\n",
    "# ax[4].plot(x, y_predict[:,4], 'b*', lw=0.1, label='standSit')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "y_predict = model.predict(test_x)\n",
    "print(y_predict.shape) # (6161, 5)  , sliding window size \n",
    "print(y_predict.argmax(axis=1)) \n",
    "print(test_y_secs[y_predict.argmax(axis=1)])\n",
    "\n",
    "x = np.arange(len(y_predict))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=5, ncols=1, figsize=(20, 10))\n",
    "ax[0].plot(x, y_predict[:,0], 'r--', lw=1, label='sitting')\n",
    "ax[1].plot(x, y_predict[:,1], 'b--', lw=1, label='sitStand')\n",
    "ax[2].plot(x, y_predict[:,2], 'g--', lw=1, label='walking')\n",
    "ax[3].plot(x, y_predict[:,3], 'r--', lw=1, label='Turning')\n",
    "ax[4].plot(x, y_predict[:,4], 'b--', lw=1, label='standSit')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  (array([], dtype=int64),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-1f83da0deaf2>:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  correct = np.nonzero(y_pred == y_test)\n",
      "<ipython-input-13-1f83da0deaf2>:5: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  incorrect = np.nonzero(y_pred != y_test)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1f83da0deaf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     plt.title(\"Predicted:{}\\nTrue:{}\".format(activity_types[y_pred[cor]-1], \n\u001b[1;32m     15\u001b[0m                                               activity_types[y_test[cor]-1]))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABOCAYAAAD4kJKWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAD10lEQVR4nO2dTYsUVxSGn1ejm9m4mAFFQzAwOEwWgjZ+bMJsAjoE3GShm0A2QyT+AFfmPySEyCxE3OhSBlHc6kaxJ0TRgDAKIUMCGSMokqAIJ4suk6GnP67lvVYdOA8UdPe9VX24D9VUnzr3lsyMwC+bmg4geDdCoHNCoHNCoHNCoHNCoHPGCpR0TtKfku4PaZek7yStSLonaV/+MINhpJyB54EjI9qPAtPVtgD8+O5hBamMFWhmN4CnI7ocAy5Yj1vANkk7cgUYjOaDDMfYCfy27v1q9dkf/R0lLdA7S5mYmNg/MzOT4ev9s7y8/MTMpursm0OgBnw2MD9nZovAIkCn07Fut5vh6/0j6de6++a4Cl0FPlz3fhfwe4bjBgnkELgEfFldjR4CnpnZhp/PoAxjf0IlXQTmgElJq8C3wBYAMzsLXAXmgRXgb+CrUsEGGxkr0MxOjGk34JtsEQVvRWRinBMCnRMCnRMCnRMCnRMCnRMCnRMCnRMCnRMCnRMCnRMCnRMCnZMkUNIRSQ+ryrPTA9rnJD2T9HO1nckfajCIlPuBm4EfgM/o3X2/I2nJzH7p63rTzD4vEGMwgpQz8ACwYmaPzewVcIleJVrQAlIEDqs66+ewpLuSrkn6ZNCBJC1I6krqrq2t1Qg36CdFYErV2U/AR2a2F/geuDzoQGa2aGYdM+tMTdWqogv6SBE4turMzJ6b2Yvq9VVgi6TJbFEGQ0kReAeYlrRb0lbgOL1KtP+QtF2SqtcHquP+lTvYYCMpRU2vJZ0CrgObgXNm9kDS11X7WeAL4KSk18A/wHGLyffvBTU1zlGZ/T+Sls2sU2ffyMQ4JwQ6JwQ6JwQ6JwQ6JwQ6JwQ6JwQ6JwQ6JwQ6JwQ6JwQ6JwQ6J1dVWqyX1hApi929qUo7CswCJyTN9nWL9dIaIldVWqyX1hApS20Nqko7mNBnw3pp69dKA14OW8LyPTMJPGk4hj11d0wRmFKVlrRe2vq10iR1696Fzkkb4pBUuzQhS1VaYp+gAFmq0oj10hojV1VanfXSFmtHnZc2xFE7hsaq0oI8RCbGOSHQOcUFtiEN14YJqsUe32BmxTZ6Fz2PgI+BrcBdYLavzzxwjd5/yUPA7QZimAOuFB6LT4F9wP0h7bXGofQZ2IY0XCsmqFqhxzeUFpgyOTR1AmnJGCBhgmphao1DjscOjCJbGq5wDG8mqL6QNE9vgup0xhhSqDUOpc/ANqThvExQrTUOpQW2IQ3nZYJqrXEo+hNaMA2XO4biE1RV6PENkUpzTmRinBMCnRMCnRMCnRMCnRMCnRMCnfMvL7qtZk44vfMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = test_y[y_predict.argmax(axis=1)]\n",
    "y_test =np.argmax(test_y,axis=1)\n",
    "\n",
    "correct = np.nonzero(y_pred == y_test)\n",
    "incorrect = np.nonzero(y_pred != y_test)\n",
    "print(\"correct: \", correct)\n",
    "\n",
    "### Check the correctly-predicted samples\n",
    "plt.figure(1)\n",
    "for i, cor in enumerate(correct[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.subplots_adjust(hspace=1.0,wspace=1.0)\n",
    "    plt.plot(test_x.iloc[cor,:])\n",
    "    plt.title(\"Predicted:{}\\nTrue:{}\".format(activity_types[y_pred[cor]-1], \n",
    "                                              activity_types[y_test[cor]-1]))\n",
    "    plt.xticks([]) # turn off x labels\n",
    "    plt.yticks([])  # turn off y labels\n",
    "    #plt.tight_layout()\n",
    "plt.show()\n",
    "### Check the incorrectly-predicted samples\n",
    "plt.figure(2)\n",
    "for i, cor in enumerate(incorrect[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.subplots_adjust(hspace=1.0,wspace=1.0)\n",
    "    plt.plot(test_x.iloc[cor,:])\n",
    "    plt.title(\"Predicted:{}\\nTrue:{}\".format(activity_types[y_pred[cor]-1], \n",
    "                                              activity_types[y_test[cor]-1]))\n",
    "    plt.xticks([]) # turn off x labels\n",
    "    plt.yticks([])  # turn off y labels\n",
    "    #plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Confusion matrix (predictive performance on different classes)\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    function provided by sklearn example\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(cnf_matrix, classes=activity_types,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
