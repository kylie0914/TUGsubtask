{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as kb\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import RNN, LSTM, TimeDistributed, LSTMCell, RNN, Dense\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from itertools import combinations\n",
    "from scipy.signal import find_peaks, butter, filtfilt, lfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peakDetector(array, threshold):\n",
    "    peaks = []\n",
    "    idx_start = 0\n",
    "    idx_end = 2\n",
    "    \n",
    "    while(idx_end < len(array)):\n",
    "        tmp = array[idx_start:idx_end+1]\n",
    "        max_ = np.max(tmp)\n",
    "        maxidx_ = np.argmax(tmp)\n",
    "        \n",
    "        if maxidx_ == 0:\n",
    "            idx_start += 1\n",
    "            idx_end = idx_start + 2\n",
    "            \n",
    "        else:\n",
    "            min1 = np.min(tmp[0:maxidx_])\n",
    "            min2 = np.min(tmp[maxidx_:len(tmp)])\n",
    "            \n",
    "            if min1 + threshold < max_ and min2 + threshold < max_:\n",
    "                peaks.append(maxidx_ + idx_start)\n",
    "                idx_start = idx_end + 1\n",
    "                idx_end = idx_start + 2\n",
    "            else:\n",
    "                idx_end += 1\n",
    "        \n",
    "    if len(peaks) > 0:\n",
    "        return True, peaks\n",
    "    else:\n",
    "        return False, peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass_filter_3d(data, cutoff, fs, order):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    # Get the filter coefficients \n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    x = filtfilt(b, a, data[:, 0])\n",
    "    y = filtfilt(b, a, data[:, 1])\n",
    "    z = filtfilt(b, a, data[:, 2])\n",
    "    result = np.stack((x, y), axis=1)\n",
    "    result = np.append(result, np.expand_dims(z, axis=1), axis=1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def getKneeAngle(a, b, c):\n",
    "    b2a = a - b\n",
    "    b2c = c - b\n",
    "    b2a_norm = np.linalg.norm(b2a, axis = 1)\n",
    "    b2c_norm = np.linalg.norm(b2c, axis = 1)\n",
    "    inner = np.diag(np.inner(b2a, b2c))\n",
    "    angle = 180 - np.arccos(inner/(b2a_norm * b2c_norm)) * 180 / np.pi\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHipAngle(a, b, c, d):\n",
    "    b2a = a - b\n",
    "    c2d = d - c\n",
    "    b2a_norm = np.linalg.norm(b2a, axis = 1)\n",
    "    c2d_norm = np.linalg.norm(c2d, axis = 1)\n",
    "    inner = np.diag(np.inner(b2a, c2d))\n",
    "    angle = 180 - np.arccos(inner/(b2a_norm * c2d_norm)) * 180 / np.pi\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getZebirsData(file):\n",
    "    path_l = os.path.join(file, \"butterfly_force_curve-L.csv\")\n",
    "    path_r = os.path.join(file, \"butterfly_force_curve-R.csv\")\n",
    "    \n",
    "    csv_data_l = np.loadtxt(path_l, delimiter=',', skiprows=4, usecols=range(2), encoding='utf-8')\n",
    "    Ltime = csv_data_l[:,0]\n",
    "    Lforce = csv_data_l[:,1]\n",
    "\n",
    "    l_contact = []\n",
    "    l_off = []\n",
    "    l_contact.append(Ltime[0])\n",
    "    pre = Ltime[0]\n",
    "    for i in Ltime:\n",
    "        if i - pre > 0.2:\n",
    "            l_contact.append(i)\n",
    "            if pre != 0:\n",
    "                l_off.append(pre)\n",
    "        pre = i\n",
    "    l_off.append(Ltime[-1])\n",
    "\n",
    "\n",
    "    csv_data_r = np.loadtxt(path_r, delimiter=',', skiprows=4, usecols=range(2), encoding='utf-8')\n",
    "    Rtime = csv_data_r[:,0]\n",
    "    Rforce = csv_data_r[:,1]\n",
    "\n",
    "    r_contact = []\n",
    "    r_off = []\n",
    "    r_contact.append(Rtime[0])\n",
    "    pre = Rtime[0]\n",
    "    for i in Rtime:\n",
    "        if i - pre > 0.2:\n",
    "            r_contact.append(i)\n",
    "            if pre != 0:\n",
    "                r_off.append(pre)\n",
    "        pre = i\n",
    "    r_off.append(Rtime[-1])\n",
    "    \n",
    "    if r_contact[0] == 0.01:\n",
    "        return True, l_contact, l_off, r_contact, r_off\n",
    "    else:\n",
    "        return False, l_contact, l_off, r_contact, r_off\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAzureData(file):\n",
    "    csv_data = np.loadtxt(file, delimiter=',', skiprows=2, usecols=(101))\n",
    "\n",
    "    idx_footSwitch = 0\n",
    "    for i in csv_data:\n",
    "        if i==0:\n",
    "            idx_footSwitch+=1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    \n",
    "    csv_data_ = np.loadtxt(file, delimiter=',', dtype=str, skiprows=2, usecols=(1))\n",
    "    line_num=csv_data_.shape[0]\n",
    "    for i, v in enumerate(csv_data_):\n",
    "        if v == \" \":\n",
    "            line_num = i\n",
    "            break\n",
    "    csv_data = np.loadtxt(file, delimiter=',', skiprows=2, max_rows=line_num, usecols=range(1, 101))\n",
    "    \n",
    "    \n",
    "    #print(csv_data)\n",
    "    \n",
    "    #print(csv_data.shape)\n",
    "    time = csv_data[:,(96, 97, 98, 99)]\n",
    "    time_ = time[:, 0] * 3600 + time[:,1] * 60 + time[:, 2]+ time[:, 3] / 1000.0\n",
    "    time_ = time_ - time_[0]\n",
    "    initialContactTime = time_[idx_footSwitch]\n",
    "    \n",
    "    cutoff = 10\n",
    "\n",
    "    pelvis_idx = 0\n",
    "    spine_naval_idx = 1\n",
    "    spine_chest_idx = 2\n",
    "    neck_idx = 3\n",
    "    \n",
    "    Pelvis = csv_data[:,pelvis_idx * 3:(pelvis_idx + 1) * 3]\n",
    "    Spine_naval = csv_data[:,spine_naval_idx * 3:(spine_naval_idx + 1) * 3]\n",
    "    Spine_chest = csv_data[:,spine_chest_idx * 3:(spine_chest_idx + 1) * 3]\n",
    "    Neck = csv_data[:,neck_idx * 3:(neck_idx + 1) * 3]\n",
    "    \n",
    "    Pelvis_filtered = butter_lowpass_filter_3d(Pelvis, cutoff, 60, 3)\n",
    "    Spine_naval_filtered = butter_lowpass_filter_3d(Spine_naval, cutoff, 60, 3)\n",
    "    Spine_chest_filtered = butter_lowpass_filter_3d(Spine_chest, cutoff, 60, 3)\n",
    "    Neck_filtered = butter_lowpass_filter_3d(Neck, cutoff, 60, 3)\n",
    "    \n",
    "    Angle_chest_filtered = getKneeAngle(Neck_filtered, Spine_chest_filtered, Spine_naval_filtered)\n",
    "    Angle_naval_filtered = getKneeAngle(Spine_chest_filtered, Spine_naval_filtered, Pelvis_filtered)\n",
    "    \n",
    "    Angle_chest = getKneeAngle(Neck, Spine_chest, Spine_naval)\n",
    "    Angle_naval = getKneeAngle(Spine_chest, Spine_naval, Pelvis)\n",
    "    \n",
    "    safe_start=0\n",
    "    safe_end=0\n",
    "    \n",
    "    \n",
    "    for i, v in enumerate(Pelvis[:, 2]):\n",
    "        if safe_start == 0 and v < 3300:\n",
    "            safe_start = i\n",
    "        if safe_start != 0 and v < 1100:\n",
    "            safe_end = i\n",
    "            break\n",
    "    \n",
    "    LHip_idx = 18 \n",
    "    LKnee_idx = 19\n",
    "    LAnkle_idx = 20\n",
    "    RHip_idx = 22\n",
    "    RKnee_idx = 23\n",
    "    RAnkle_idx = 24\n",
    "\n",
    "    LHip = csv_data[:, LHip_idx * 3: (LHip_idx + 1) * 3]\n",
    "    LKnee = csv_data[:, LKnee_idx * 3: (LKnee_idx + 1) * 3]\n",
    "    LAnkle = csv_data[:, LAnkle_idx * 3: (LAnkle_idx + 1) * 3]\n",
    "    LHip_filtered = butter_lowpass_filter_3d(LHip, cutoff, 60, 3)\n",
    "    LKnee_filtered = butter_lowpass_filter_3d(LKnee, cutoff, 60, 3)\n",
    "    LAnkle_filtered = butter_lowpass_filter_3d(LAnkle, cutoff, 60, 3)\n",
    "    LAngle_knee_filtered = getKneeAngle(LHip_filtered, LKnee_filtered, LAnkle_filtered)\n",
    "    LAngle_hip_filtered = getHipAngle(Spine_chest_filtered, Pelvis_filtered, LHip_filtered, LKnee_filtered)\n",
    "    LAngle_knee = getKneeAngle(LHip, LKnee, LAnkle)\n",
    "    LAngle_hip = getHipAngle(Spine_chest, Pelvis, LHip, LKnee)\n",
    "\n",
    "\n",
    "    RHip = csv_data[:, RHip_idx * 3: (RHip_idx + 1) * 3]\n",
    "    RKnee = csv_data[:, RKnee_idx * 3: (RKnee_idx + 1) * 3]\n",
    "    RAnkle = csv_data[:, RAnkle_idx * 3: (RAnkle_idx + 1) * 3]\n",
    "    RHip_filtered = butter_lowpass_filter_3d(RHip, cutoff, 60, 3)\n",
    "    RKnee_filtered = butter_lowpass_filter_3d(RKnee, cutoff, 60, 3)\n",
    "    RAnkle_filtered = butter_lowpass_filter_3d(RAnkle, cutoff, 60, 3)\n",
    "    RAngle_knee_filtered = getKneeAngle(RHip_filtered, RKnee_filtered, RAnkle_filtered)\n",
    "    RAngle_hip_filtered = getHipAngle(Spine_chest_filtered, Pelvis_filtered, RHip_filtered, RKnee_filtered)\n",
    "    RAngle_knee = getKneeAngle(RHip, RKnee, RAnkle)\n",
    "    RAngle_hip = getHipAngle(Spine_chest, Pelvis, RHip, RKnee)\n",
    "    \n",
    "    \n",
    "    return Angle_chest_filtered, Angle_naval_filtered, LAngle_hip_filtered, LAngle_knee_filtered, RAngle_hip_filtered, RAngle_knee_filtered, time_, initialContactTime\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = []\n",
    "\n",
    "class EarlyStoppingAtMinLoss(keras.callbacks.Callback):\n",
    "    global path_dataset\n",
    "    global result\n",
    "    def __init__(self, patience=10):\n",
    "        super(EarlyStoppingAtMinLoss, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = np.Inf\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(\"loss\")\n",
    "        if np.less(current, self.best):\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait +=1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                self.model.set_weights(self.best_weights)\n",
    "                \n",
    "    def on_train_end(self, logs=None):\n",
    "        global result\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch %05d: early stopping\" %(self.stopped_epoch + 1))\n",
    "        \n",
    "        coverage = getCoverage(path_dataset, self.model.train_names, self.model)\n",
    "        result.append(coverage)\n",
    "        print(self.model.train_names)\n",
    "        print(coverage)\n",
    "        \n",
    "        tmp = list(combinations(names, 6))\n",
    "        idx_ = tmp.index(self.model.train_names)\n",
    "        ratio = self.model.ratio\n",
    "        if idx_ == len(tmp)-1:\n",
    "            \n",
    "            for i in result:\n",
    "                f = open('result.txt', 'a')\n",
    "                f.write(str(i) + '\\n')\n",
    "                f.close()\n",
    "                \n",
    "            print(result)\n",
    "\n",
    "            if ratio-5 < 20:\n",
    "                return\n",
    "            else:\n",
    "                f = open('result.txt', 'a')\n",
    "                f.write('ratio : ' + str(ratio - 5) + '\\n')\n",
    "                f.close()\n",
    "                result = []\n",
    "                startNewSession(ratio-5, tmp[0])\n",
    "                \n",
    "        else:\n",
    "            startNewSession(ratio, tmp[idx_+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d8168b4a01c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[0mtrain_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# path_dataset = \"Dataset\"\n",
    "path_dataset =\"dataset\"\n",
    "startRatio = 45\n",
    "\n",
    "def startNewSession(ratio, train_names):\n",
    "    epoch = 200\n",
    "    model = RNN(ratio, train_names)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(0.001),loss=custom_loss(ratio),metrics=['accuracy'])\n",
    "    model.fit(model.dataset, verbose=0, epochs=epoch, callbacks=[EarlyStoppingAtMinLoss()])\n",
    "    \n",
    "    \n",
    "def custom_loss(ratio_):\n",
    "    def loss(y_actual,y_pred):\n",
    "        y_ = kb.sigmoid(y_pred)\n",
    "        loss_ = ratio_ * y_actual * kb.log(y_) + (1- y_actual) * kb.log(1 - y_)\n",
    "        return -tf.reduce_mean(loss_)\n",
    "    return loss\n",
    "\n",
    "class RNN(Model):\n",
    "    global path_dataset\n",
    "    def __init__(self, ratio_, train_names_):\n",
    "        super().__init__()\n",
    "        self.ratio = ratio_\n",
    "        self.train_names = train_names_\n",
    "        self.lstm1 = LSTM(15, return_sequences=True)\n",
    "        self.lstm2 = LSTM(10, return_sequences=True)\n",
    "        self.lastLayer = TimeDistributed(Dense(1, activation = 'sigmoid'))\n",
    "        \n",
    "        self.dataset = getDataset(path_dataset, train_names)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.lstm1(inputs)\n",
    "        x = self.lstm2(x)\n",
    "        x = self.lastLayer(x)\n",
    "        print('rnn', x.shape)\n",
    "        return x\n",
    "    \n",
    "names = next(os.walk(path_dataset))[1]\n",
    "train_names = list(combinations(names, 6))[0]\n",
    "\n",
    "f = open('result.txt', 'a')\n",
    "f.write('ratio : ' + str(startRatio) + '\\n')\n",
    "f.close()\n",
    "\n",
    "startNewSession(startRatio, train_names)\n",
    "                \n",
    "                \n",
    "                \n",
    "#startNewSession(50, train_names)\n",
    "    \n",
    "\"\"\"\n",
    "                while(l_off[-1] > time[-1]):\n",
    "                    l_off = l_off[:-1]\n",
    "\n",
    "                while(r_off[-1] > time[-1]):\n",
    "                    r_off = r_off[:-1]\n",
    "\n",
    "\n",
    "                fig, ax = plt.subplots(2, figsize=(18,12))\n",
    "                ax[0].plot(time, LKnee, 'r-', label = 'LKnee')\n",
    "                ax[0].plot(time, LHip, 'b-', label = 'LHip')\n",
    "                ax[0].axvline(x = initialContactTime, label='foot switch on ! at x = {}'.format(initialContactTime), c='b')\n",
    "                for i in l_contact:\n",
    "                    ax[0].axvline(x=i, label='contact ! at x = {}'.format(i), c='k')\n",
    "                for i in l_off:\n",
    "                    ax[0].axvline(x=i, label='off ! at x = {}'.format(i), c='k', ls = '--')\n",
    "                ax[0].axis((time[0], time[-1], 0, 90))\n",
    "\n",
    "\n",
    "                ax[1].plot(time, RKnee, 'r-', label = 'RKnee')\n",
    "                ax[1].plot(time, RHip, 'b-', label = 'RHip')\n",
    "                ax[1].axvline(x = initialContactTime, label='foot switch on ! at x = {}'.format(initialContactTime), c='b')\n",
    "                for i in r_contact:\n",
    "                    ax[1].axvline(x=i, label='contact ! at x = {}'.format(i), c='k')\n",
    "                for i in r_off:\n",
    "                    ax[1].axvline(x=i, label='off ! at x = {}'.format(i), c='k', ls = '--')\n",
    "                ax[1].axis((time[0], time[-1], 0, 90))\n",
    "\n",
    "                fig.tight_layout()\n",
    "                print('2020_11_06_synced//' + name + path_zebris[idx] + '.png')\n",
    "                plt.savefig('2020_11_06_synced//' + name + path_zebris[idx] + '.png')\n",
    "                plt.close()\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                                fig, ax = plt.subplots(2, figsize=(18,12))\n",
    "                ax[0].plot(time, LKnee, 'r-', label = 'LKnee')\n",
    "                ax[0].plot(time, LHip, 'b-', label = 'LHip')\n",
    "                ax[0].axvline(x = initialContactTime, label='foot switch on ! at x = {}'.format(initialContactTime), c='b')\n",
    "                for i in l_contact:\n",
    "                    ax[0].axvline(x=i, label='contact ! at x = {}'.format(i), c='k')\n",
    "                ax[0].axvline(x=time[safe_start], label='safe_start at x = {}'.format(i), c='g')\n",
    "                ax[0].axvline(x=time[safe_end], label='safe_end at x = {}'.format(i), c='g')\n",
    "                ax[0].axis((time[0], time[-1], 0, 90))\n",
    "\n",
    "                # INPUT\n",
    "                x_new = np.linspace(time[0], time[-1], len(time))\n",
    "\n",
    "                f = interpolate.interp1d(time, Chest)\n",
    "                Chest_ = f(x_new)\n",
    "                f = interpolate.interp1d(time, Naval)\n",
    "                Naval_ = f(x_new)\n",
    "                f = interpolate.interp1d(time, LKnee)\n",
    "                LKnee_ = f(x_new)\n",
    "                f = interpolate.interp1d(time, LHip)\n",
    "                LHip_ = f(x_new)\n",
    "                f = interpolate.interp1d(time, RKnee)\n",
    "                RKnee_ = f(x_new)\n",
    "                f = interpolate.interp1d(time, RHip)\n",
    "                RHip_ = f(x_new)\n",
    "\n",
    "                RLinput = np.concatenate((np.expand_dims(Chest_, axis=1), np.expand_dims(Naval_, axis=1), np.expand_dims(LKnee_, axis=1), np.expand_dims(LHip_, axis=1), np.expand_dims(RKnee_, axis=1), np.expand_dims(RHip_, axis=1)), axis=1) \n",
    "                min_ = np.expand_dims(np.min(RLinput,axis=0), axis=0)\n",
    "                max_ = np.expand_dims(np.max(RLinput,axis=0), axis=0)\n",
    "                RLinput = (RLinput - min_) / (max_ - min_)\n",
    "\n",
    "                # OUTPUT\n",
    "                Lcontact_output = np.zeros(len(Chest))\n",
    "                for i in l_contact:\n",
    "                    tmp = abs(time - i)\n",
    "                    Lcontact_output[np.argmin(tmp)] = 1\n",
    "\n",
    "\n",
    "\n",
    "                for idx_ in range(safe_start, safe_end - 40):\n",
    "                    count_total +=1\n",
    "\n",
    "                    #RLinput = np.concatenate((np.expand_dims(Chest, axis=1), np.expand_dims(Naval, axis=1), np.expand_dims(LKnee, axis=1), np.expand_dims(LHip, axis=1), np.expand_dims(RKnee, axis=1), np.expand_dims(RHip, axis=1)), axis=1) \n",
    "                    testinput = np.expand_dims(RLinput[idx_: idx_+40], axis=0)\n",
    "                    #min_input = np.expand_dims(np.min(testinput,axis=1), axis=0)\n",
    "                    #max_input = np.expand_dims(np.max(testinput,axis=1), axis=0)\n",
    "                    #testinput = (testinput - min_input) / (max_input - min_input)\n",
    "                    print(model.predict(testinput).shape)\n",
    "                    output_predicted = np.squeeze(model.predict(testinput))\n",
    "                    answer = Lcontact_output[idx_:idx_+40]\n",
    "\n",
    "                    flag, peaks = peakDetector(output_predicted, 0.5)\n",
    "                    x = time[idx_:idx_+40]\n",
    "                    if flag:\n",
    "                        if np.count_nonzero(answer == 1) == len(peaks):\n",
    "                            ax[1].plot(x[peaks], output_predicted[peaks], 'g.')\n",
    "                            count_positive += 1\n",
    "                        else:\n",
    "                            ax[1].plot(x[peaks], output_predicted[peaks] / 2, 'r.')\n",
    "                    else:\n",
    "                        if np.count_nonzero(answer == 1) == 0:\n",
    "                            count_positive += 1\n",
    "                        else:\n",
    "                            ax[1].plot(x[peaks], output_predicted[peaks] / 3 * 2, 'k.')\n",
    "\n",
    "\n",
    "\n",
    "                    #\n",
    "                    #ax[1].plot(x, output_predicted, 'k.')\n",
    "\n",
    "                for i in l_contact:\n",
    "                    ax[1].axvline(x=i, label='contact ! at x = {}'.format(i), c='y')\n",
    "                ax[1].axvline(x=time[safe_start], label='safe_start at x = {}'.format(i), c='g')\n",
    "                ax[1].axvline(x=time[safe_end], label='safe_end at x = {}'.format(i), c='g')\n",
    "                ax[1].axis((time[0], time[-1], 0, 1.2))\n",
    "\n",
    "\n",
    "                fig.tight_layout()\n",
    "                #print('2020_11_06_testResult//' + name + path_zebris[idx] + '.png')\n",
    "                #plt.savefig('2020_11_06_testResult//' + name + path_zebris[idx] + '.png')\n",
    "                plt.close()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = \"Dataset\"\n",
    "def getDataset(path_dataset, train_names):\n",
    "    totalDataset = None\n",
    "    numFrame = 40\n",
    "    for name in next(os.walk(path_dataset))[1]:\n",
    "        if name in train_names:\n",
    "            #print(name)\n",
    "            path_person = os.path.join(path_dataset, name)\n",
    "            (root, path_zebris, path_azure) = next(os.walk(path_person))\n",
    "            if '.ipynb_checkpoints' in path_zebris:\n",
    "                path_zebris.remove('.ipynb_checkpoints')\n",
    "            path_zebris = sorted(path_zebris)\n",
    "            path_azure = sorted(path_azure)\n",
    "            \n",
    "            for idx in range(len(path_zebris)):\n",
    "                #print(path_zebris[idx])\n",
    "                Chest, Naval, LHip, LKnee, RHip, RKnee, time, initialContactTime = getAzureData(os.path.join(path_person, path_azure[idx]))\n",
    "                firstStep, l_contact, l_off, r_contact, r_off = getZebirsData(os.path.join(path_person, path_zebris[idx]))\n",
    "\n",
    "                timeGap = initialContactTime - r_contact[0]\n",
    "                l_contact = l_contact + timeGap\n",
    "                l_off = l_off + timeGap\n",
    "                r_contact = r_contact + timeGap\n",
    "                r_off = r_off + timeGap\n",
    "                \n",
    "                # INPUT\n",
    "                x_new = np.linspace(time[0], time[-1], len(time))\n",
    "\n",
    "                f = interpolate.interp1d(time, Chest)\n",
    "                Chest_ = f(x_new)\n",
    "                f = interpolate.interp1d(time, Naval)\n",
    "                Naval_ = f(x_new)\n",
    "                f = interpolate.interp1d(time, LKnee)\n",
    "                LKnee_ = f(x_new)\n",
    "                f = interpolate.interp1d(time, LHip)\n",
    "                LHip_ = f(x_new)\n",
    "                f = interpolate.interp1d(time, RKnee)\n",
    "                RKnee_ = f(x_new)\n",
    "                f = interpolate.interp1d(time, RHip)\n",
    "                RHip_ = f(x_new)\n",
    "\n",
    "                RLinput = np.concatenate((np.expand_dims(Chest_, axis=1), np.expand_dims(Naval_, axis=1), np.expand_dims(LKnee_, axis=1), np.expand_dims(LHip_, axis=1), np.expand_dims(RKnee_, axis=1), np.expand_dims(RHip_, axis=1)), axis=1) \n",
    "                min_ = np.expand_dims(np.min(RLinput,axis=0), axis=0)\n",
    "                max_ = np.expand_dims(np.max(RLinput,axis=0), axis=0)\n",
    "                RLinput = (RLinput - min_) / (max_ - min_)\n",
    "\n",
    "                # OUTPUT\n",
    "                Lcontact_output = np.zeros(len(Chest))\n",
    "                for i in l_contact:\n",
    "                    tmp = abs(time - i)\n",
    "                    Lcontact_output[np.argmin(tmp)] = 1\n",
    "\n",
    "                # Slicing\n",
    "                inputs =  np.empty((1, numFrame, RLinput.shape[1]), dtype=float)\n",
    "                outputs = np.empty((1, numFrame), dtype=float)\n",
    "\n",
    "                tmp = abs(time - r_contact[0])\n",
    "                safe_start = np.argmin(tmp)\n",
    "\n",
    "                tmp = abs(time - max(l_off[-1], r_off[-1]))\n",
    "                safe_end = np.argmin(tmp)\n",
    "\n",
    "\n",
    "                idx_end = numFrame\n",
    "\n",
    "\n",
    "                while(idx_end <safe_end):\n",
    "                    if(idx_end - numFrame > safe_start):\n",
    "                        input_ = np.expand_dims(RLinput[idx_end - numFrame: idx_end], axis=0)\n",
    "                        output_ = np.expand_dims(Lcontact_output[idx_end - numFrame:idx_end], axis=0)\n",
    "\n",
    "                        inputs = np.append(inputs, input_, axis=0)\n",
    "                        outputs = np.append(outputs, output_, axis=0)\n",
    "                    idx_end +=1\n",
    "\n",
    "                inputs = np.delete(inputs, [0,0,0], axis=0)\n",
    "                outputs = np.delete(outputs, [0,0], axis=0)\n",
    "\n",
    "                dataset = tf.data.Dataset.from_tensor_slices((inputs.astype('float32'), outputs.astype('float32')))\n",
    "                if totalDataset == None:\n",
    "                    totalDataset = dataset\n",
    "                else:\n",
    "                    totalDataset = totalDataset.concatenate(dataset)\n",
    "                    #dataset_shuffled = dataset.shuffle(10000).batch(32, drop_remainder = True)\n",
    "                    \n",
    "    return totalDataset.shuffle(10000).batch(32, drop_remainder = True)\n",
    "                    \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = \"Dataset\"\n",
    "def getCoverage(path_dataset, train_names, model):\n",
    "    \n",
    "    count_total=0\n",
    "    count_positive=0\n",
    "\n",
    "    for name in next(os.walk(path_dataset))[1]:\n",
    "        if name not in train_names:\n",
    "            #print(name)\n",
    "            path_person = os.path.join(path_dataset, name)\n",
    "            (root, path_zebris, path_azure) = next(os.walk(path_person))\n",
    "            if '.ipynb_checkpoints' in path_zebris:\n",
    "                path_zebris.remove('.ipynb_checkpoints')\n",
    "            path_zebris = sorted(path_zebris)\n",
    "            path_azure = sorted(path_azure)\n",
    "            for idx in range(len(path_zebris)):\n",
    "                #print(path_zebris[idx])\n",
    "                \n",
    "                Chest, Naval, LHip, LKnee, RHip, RKnee, time, initialContactTime = getAzureData(os.path.join(path_person, path_azure[idx]))\n",
    "                firstStep, l_contact, l_off, r_contact, r_off = getZebirsData(os.path.join(path_person, path_zebris[idx]))\n",
    "\n",
    "                timeGap = initialContactTime - r_contact[0]\n",
    "                l_contact = l_contact + timeGap\n",
    "                l_off = l_off + timeGap\n",
    "                r_contact = r_contact + timeGap\n",
    "                r_off = r_off + timeGap\n",
    "\n",
    "                \"\"\"\n",
    "                while((len(l_off) > 0) and (l_off[-1] > time[-1])):\n",
    "                    l_off = l_off[:-1]\n",
    "\n",
    "                while((len(r_off) > 0) and (l_off[-1] > time[-1])):\n",
    "                    r_off = r_off[:-1]\n",
    "\n",
    "                \"\"\"\n",
    "                \n",
    "                tmp = abs(time - r_contact[0])\n",
    "                safe_start = np.argmin(tmp)\n",
    "\n",
    "                tmp = abs(time - max(l_off[-1], r_off[-1]))\n",
    "                safe_end = np.argmin(tmp)\n",
    "                \n",
    "                # INPUT\n",
    "                x_new = np.linspace(time[0], time[-1], len(time))\n",
    "\n",
    "                f = interpolate.interp1d(time, Chest)\n",
    "                Chest_ = f(x_new)\n",
    "                f = interpolate.interp1d(time, Naval)\n",
    "                Naval_ = f(x_new)\n",
    "                f = interpolate.interp1d(time, LKnee)\n",
    "                LKnee_ = f(x_new)\n",
    "                f = interpolate.interp1d(time, LHip)\n",
    "                LHip_ = f(x_new)\n",
    "                f = interpolate.interp1d(time, RKnee)\n",
    "                RKnee_ = f(x_new)\n",
    "                f = interpolate.interp1d(time, RHip)\n",
    "                RHip_ = f(x_new)\n",
    "\n",
    "                RLinput = np.concatenate((np.expand_dims(Chest_, axis=1), np.expand_dims(Naval_, axis=1), np.expand_dims(LKnee_, axis=1), np.expand_dims(LHip_, axis=1), np.expand_dims(RKnee_, axis=1), np.expand_dims(RHip_, axis=1)), axis=1) \n",
    "                min_ = np.expand_dims(np.min(RLinput,axis=0), axis=0)\n",
    "                max_ = np.expand_dims(np.max(RLinput,axis=0), axis=0)\n",
    "                RLinput = (RLinput - min_) / (max_ - min_)\n",
    "\n",
    "                # OUTPUT\n",
    "                Lcontact_output = np.zeros(len(Chest))\n",
    "                for i in l_contact:\n",
    "                    tmp = abs(time - i)\n",
    "                    Lcontact_output[np.argmin(tmp)] = 1\n",
    "\n",
    "\n",
    "\n",
    "                for idx_ in range(safe_start, safe_end - 40):\n",
    "                    count_total +=1\n",
    "                    testinput = np.expand_dims(RLinput[idx_: idx_+40], axis=0)\n",
    "                    output_predicted = np.squeeze(model.predict(testinput))\n",
    "                    answer = Lcontact_output[idx_:idx_+40]\n",
    "\n",
    "                    flag, peaks = peakDetector(output_predicted, 0.5)\n",
    "                    x = time[idx_:idx_+40]\n",
    "                    if flag:\n",
    "                        if np.count_nonzero(answer == 1) == len(peaks):\n",
    "                            count_positive += 1\n",
    "                    else:\n",
    "                        if np.count_nonzero(answer == 1) == 0:\n",
    "                            count_positive += 1\n",
    "                            \n",
    "    return count_positive * 100 / count_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = \"2020_11_06\"\n",
    "for name in next(os.walk(path_dataset))[1]:\n",
    "    if name in train_names:\n",
    "        path_person = os.path.join(path_dataset, name)\n",
    "        (root, path_zebris, path_azure) = next(os.walk(path_person))\n",
    "        #print(name)\n",
    "        if '.ipynb_checkpoints' in path_zebris:\n",
    "            path_zebris.remove('.ipynb_checkpoints')\n",
    "        path_zebris = sorted(path_zebris)\n",
    "        path_azure = sorted(path_azure)\n",
    "        for idx in range(len(path_zebris)):\n",
    "            Chest, Naval, LHip, LKnee, RHip, RKnee, time, initialContactTime = getAzureData(os.path.join(path_person, path_azure[idx]))\n",
    "            firstStep, l_contact, l_off, r_contact, r_off = getZebirsData(os.path.join(path_person, path_zebris[idx]))\n",
    "\n",
    "            timeGap = initialContactTime - r_contact[0]\n",
    "            l_contact = l_contact + timeGap\n",
    "            l_off = l_off + timeGap\n",
    "            r_contact = r_contact + timeGap\n",
    "            r_off = r_off + timeGap\n",
    "\n",
    "            while(l_off[-1] > time[-1]):\n",
    "                l_off = l_off[:-1]\n",
    "\n",
    "            while(r_off[-1] > time[-1]):\n",
    "                r_off = r_off[:-1]\n",
    "\n",
    "\n",
    "            fig, ax = plt.subplots(2, figsize=(18,12))\n",
    "            ax[0].plot(time, LKnee, 'r-', label = 'LKnee')\n",
    "            ax[0].plot(time, LHip, 'b-', label = 'LHip')\n",
    "            ax[0].axvline(x = initialContactTime, label='foot switch on ! at x = {}'.format(initialContactTime), c='b')\n",
    "            for i in l_contact:\n",
    "                ax[0].axvline(x=i, label='contact ! at x = {}'.format(i), c='k')\n",
    "            for i in l_off:\n",
    "                ax[0].axvline(x=i, label='off ! at x = {}'.format(i), c='k', ls = '--')\n",
    "            ax[0].axis((time[0], time[-1], 0, 90))\n",
    "\n",
    "\n",
    "            ax[1].plot(time, RKnee, 'r-', label = 'RKnee')\n",
    "            ax[1].plot(time, RHip, 'b-', label = 'RHip')\n",
    "            ax[1].axvline(x = initialContactTime, label='foot switch on ! at x = {}'.format(initialContactTime), c='b')\n",
    "            for i in r_contact:\n",
    "                ax[1].axvline(x=i, label='contact ! at x = {}'.format(i), c='k')\n",
    "            for i in r_off:\n",
    "                ax[1].axvline(x=i, label='off ! at x = {}'.format(i), c='k', ls = '--')\n",
    "            ax[1].axis((time[0], time[-1], 0, 90))\n",
    "\n",
    "            fig.tight_layout()\n",
    "            print('2020_11_06_synced//' + name + path_zebris[idx] + '.png')\n",
    "            plt.savefig('2020_11_06_synced//' + name + path_zebris[idx] + '.png')\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "\n",
    "            # INPUT\n",
    "            x_new = np.linspace(time[0], time[-1], len(time))\n",
    "\n",
    "            f = interpolate.interp1d(time, Chest)\n",
    "            Chest_ = f(x_new)\n",
    "            f = interpolate.interp1d(time, Naval)\n",
    "            Naval_ = f(x_new)\n",
    "            f = interpolate.interp1d(time, LKnee)\n",
    "            LKnee_ = f(x_new)\n",
    "            f = interpolate.interp1d(time, LHip)\n",
    "            LHip_ = f(x_new)\n",
    "            f = interpolate.interp1d(time, RKnee)\n",
    "            RKnee_ = f(x_new)\n",
    "            f = interpolate.interp1d(time, RHip)\n",
    "            RHip_ = f(x_new)\n",
    "\n",
    "            RLinput = np.concatenate((np.expand_dims(Chest_, axis=1), np.expand_dims(Naval_, axis=1), np.expand_dims(LKnee_, axis=1), np.expand_dims(LHip_, axis=1), np.expand_dims(RKnee_, axis=1), np.expand_dims(RHip_, axis=1)), axis=1) \n",
    "            min_ = np.expand_dims(np.min(RLinput,axis=0), axis=0)\n",
    "            max_ = np.expand_dims(np.max(RLinput,axis=0), axis=0)\n",
    "            RLinput = (RLinput - min_) / (max_ - min_)\n",
    "\n",
    "            # OUTPUT\n",
    "            Lcontact_output = np.zeros(len(Chest))\n",
    "            for i in l_contact:\n",
    "                tmp = abs(time - i)\n",
    "                Lcontact_output[np.argmin(tmp)] = 1\n",
    "\n",
    "            # Slicing\n",
    "            inputs =  np.empty((1, numFrame, RLinput.shape[1]), dtype=float)\n",
    "            outputs = np.empty((1, numFrame), dtype=float)\n",
    "\n",
    "            tmp = abs(time - r_contact[0])\n",
    "            safe_start = np.argmin(tmp)\n",
    "\n",
    "            tmp = abs(time - max(l_off[-1], r_off[-1]))\n",
    "            safe_end = np.argmin(tmp)\n",
    "\n",
    "\n",
    "            idx_end = numFrame\n",
    "\n",
    "\n",
    "            while(idx_end <safe_end):\n",
    "                if(idx_end - numFrame > safe_start):\n",
    "                    input_ = np.expand_dims(RLinput[idx_end - numFrame: idx_end], axis=0)\n",
    "                    output_ = np.expand_dims(Lcontact_output[idx_end - numFrame:idx_end], axis=0)\n",
    "\n",
    "                    inputs = np.append(inputs, input_, axis=0)\n",
    "                    outputs = np.append(outputs, output_, axis=0)\n",
    "                idx_end +=1\n",
    "\n",
    "            inputs = np.delete(inputs, [0,0,0], axis=0)\n",
    "            outputs = np.delete(outputs, [0,0], axis=0)\n",
    "\n",
    "            dataset = tf.data.Dataset.from_tensor_slices((inputs.astype('float32'), outputs.astype('float32')))\n",
    "            if totalDataset == None:\n",
    "                totalDataset = dataset\n",
    "            else:\n",
    "                totalDataset = totalDataset.concatenate(dataset)\n",
    "\n",
    "                \n",
    "    \n",
    "epoch = 100\n",
    "model = RNN()\n",
    "\n",
    "dataset_shuffled = totalDataset.shuffle(10000).batch(32, drop_remainder = True)\n",
    "model.compile(optimizer=keras.optimizers.Adam(0.001),loss=custom_loss,metrics=['accuracy'])\n",
    "model.fit(dataset_shuffled, epochs=epoch)\n",
    "\n",
    "#model_name = \"Loss_\" +str(constant)+ \"_Model\"\n",
    "#model.save(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "\n",
    "constant = 150\n",
    "\n",
    "def custom_loss(y_actual,y_pred):\n",
    "    y_ = kb.sigmoid(y_pred)\n",
    "    custom_loss = constant * y_actual * kb.log(y_) + (1- y_actual) * kb.log(1 - y_)\n",
    "    return -tf.reduce_mean(custom_loss)\n",
    "\n",
    "class RNN(Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.lstm1 = LSTM(15, return_sequences=True)\n",
    "        self.lstm2 = LSTM(10, return_sequences=True)\n",
    "        self.lastLayer = TimeDistributed(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.lstm1(inputs)\n",
    "        x = self.lstm2(x)\n",
    "        x = self.lastLayer(x)\n",
    "        print('rnn', x.shape)\n",
    "        return x\n",
    "    \n",
    "\n",
    "path_dataset = \"2020_11_06\"\n",
    "names = next(os.walk(path_dataset))[1]\n",
    "\n",
    "for number in range(1, len(names)):\n",
    "    print(number)\n",
    "    coverages = []\n",
    "    tmp = list(permutations(names, number))\n",
    "    for train_names in tmp:\n",
    "        totalDataset = None\n",
    "        for name in next(os.walk(path_dataset))[1]:\n",
    "            if name in train_names:\n",
    "                path_person = os.path.join(path_dataset, name)\n",
    "                (root, path_zebris, path_azure) = next(os.walk(path_person))\n",
    "                #print(name)\n",
    "                if '.ipynb_checkpoints' in path_zebris:\n",
    "                    path_zebris.remove('.ipynb_checkpoints')\n",
    "                path_zebris = sorted(path_zebris)\n",
    "                path_azure = sorted(path_azure)\n",
    "                for idx in range(len(path_zebris)):\n",
    "                    Chest, Naval, LHip, LKnee, RHip, RKnee, time, initialContactTime = getAzureData(os.path.join(path_person, path_azure[idx]))\n",
    "                    firstStep, l_contact, l_off, r_contact, r_off = getZebirsData(os.path.join(path_person, path_zebris[idx]))\n",
    "\n",
    "                    timeGap = initialContactTime - r_contact[0]\n",
    "                    l_contact = l_contact + timeGap\n",
    "                    l_off = l_off + timeGap\n",
    "                    r_contact = r_contact + timeGap\n",
    "                    r_off = r_off + timeGap\n",
    "\n",
    "                    while(l_off[-1] > time[-1]):\n",
    "                        l_off = l_off[:-1]\n",
    "\n",
    "                    while(r_off[-1] > time[-1]):\n",
    "                        r_off = r_off[:-1]\n",
    "                        \n",
    "                    # INPUT\n",
    "                    x_new = np.linspace(time[0], time[-1], len(time))\n",
    "\n",
    "                    f = interpolate.interp1d(time, Chest)\n",
    "                    Chest_ = f(x_new)\n",
    "                    f = interpolate.interp1d(time, Naval)\n",
    "                    Naval_ = f(x_new)\n",
    "                    f = interpolate.interp1d(time, LKnee)\n",
    "                    LKnee_ = f(x_new)\n",
    "                    f = interpolate.interp1d(time, LHip)\n",
    "                    LHip_ = f(x_new)\n",
    "                    f = interpolate.interp1d(time, RKnee)\n",
    "                    RKnee_ = f(x_new)\n",
    "                    f = interpolate.interp1d(time, RHip)\n",
    "                    RHip_ = f(x_new)\n",
    "\n",
    "                    RLinput = np.concatenate((np.expand_dims(Chest_, axis=1), np.expand_dims(Naval_, axis=1), np.expand_dims(LKnee_, axis=1), np.expand_dims(LHip_, axis=1), np.expand_dims(RKnee_, axis=1), np.expand_dims(RHip_, axis=1)), axis=1) \n",
    "                    min_ = np.expand_dims(np.min(RLinput,axis=0), axis=0)\n",
    "                    max_ = np.expand_dims(np.max(RLinput,axis=0), axis=0)\n",
    "                    RLinput = (RLinput - min_) / (max_ - min_)\n",
    "\n",
    "                    # OUTPUT\n",
    "                    Lcontact_output = np.zeros(len(Chest))\n",
    "                    for i in l_contact:\n",
    "                        tmp = abs(time - i)\n",
    "                        Lcontact_output[np.argmin(tmp)] = 1\n",
    "\n",
    "                    # Slicing\n",
    "                    inputs =  np.empty((1, numFrame, RLinput.shape[1]), dtype=float)\n",
    "                    outputs = np.empty((1, numFrame), dtype=float)\n",
    "\n",
    "                    tmp = abs(time - r_contact[0])\n",
    "                    safe_start = np.argmin(tmp)\n",
    "\n",
    "                    tmp = abs(time - max(l_off[-1], r_off[-1]))\n",
    "                    safe_end = np.argmin(tmp)\n",
    "\n",
    "\n",
    "                    idx_end = numFrame\n",
    "\n",
    "\n",
    "                    while(idx_end <safe_end):\n",
    "                        if(idx_end - numFrame > safe_start):\n",
    "                            input_ = np.expand_dims(RLinput[idx_end - numFrame: idx_end], axis=0)\n",
    "                            output_ = np.expand_dims(Lcontact_output[idx_end - numFrame:idx_end], axis=0)\n",
    "\n",
    "                            inputs = np.append(inputs, input_, axis=0)\n",
    "                            outputs = np.append(outputs, output_, axis=0)\n",
    "                        idx_end +=1\n",
    "\n",
    "                    inputs = np.delete(inputs, [0,0,0], axis=0)\n",
    "                    outputs = np.delete(outputs, [0,0], axis=0)\n",
    "\n",
    "                    dataset = tf.data.Dataset.from_tensor_slices((inputs.astype('float32'), outputs.astype('float32')))\n",
    "                    if totalDataset == None:\n",
    "                        totalDataset = dataset\n",
    "                    else:\n",
    "                        totalDataset = totalDataset.concatenate(dataset)\n",
    "        epoch = 100\n",
    "        model = RNN()\n",
    "        dataset_shuffled = totalDataset.shuffle(10000).batch(32, drop_remainder = True)\n",
    "        model.compile(optimizer=keras.optimizers.Adam(0.001),loss=custom_loss,metrics=['accuracy'])\n",
    "        model.fit(dataset_shuffled, epochs=epoch)\n",
    "        break\n",
    "        count_total = 0.0\n",
    "        count_positive = 0.0\n",
    "        \n",
    "        for name in next(os.walk(path_dataset))[1]:\n",
    "            if name not in train_names:\n",
    "                path_person = os.path.join(path_dataset, name)\n",
    "                (root, path_zebris, path_azure) = next(os.walk(path_person))\n",
    "                if '.ipynb_checkpoints' in path_zebris:\n",
    "                    path_zebris.remove('.ipynb_checkpoints')\n",
    "                path_zebris = sorted(path_zebris)\n",
    "                path_azure = sorted(path_azure)\n",
    "                for idx in range(len(path_zebris)):\n",
    "                    Chest, Naval, LHip, LKnee, RHip, RKnee, time, initialContactTime = getAzureData(os.path.join(path_person, path_azure[idx]))\n",
    "                    firstStep, l_contact, l_off, r_contact, r_off = getZebirsData(os.path.join(path_person, path_zebris[idx]))\n",
    "\n",
    "                    timeGap = initialContactTime - r_contact[0]\n",
    "                    l_contact = l_contact + timeGap\n",
    "                    l_off = l_off + timeGap\n",
    "                    r_contact = r_contact + timeGap\n",
    "                    r_off = r_off + timeGap\n",
    "\n",
    "                    while(l_off[-1] > time[-1]):\n",
    "                        l_off = l_off[:-1]\n",
    "\n",
    "                    while(r_off[-1] > time[-1]):\n",
    "                        r_off = r_off[:-1]\n",
    "\n",
    "\n",
    "                    tmp = abs(time - r_contact[0])\n",
    "                    safe_start = np.argmin(tmp)\n",
    "\n",
    "                    tmp = abs(time - max(l_off[-1], r_off[-1]))\n",
    "                    safe_end = np.argmin(tmp)\n",
    "\n",
    "                    # INPUT\n",
    "                    x_new = np.linspace(time[0], time[-1], len(time))\n",
    "\n",
    "                    f = interpolate.interp1d(time, Chest)\n",
    "                    Chest_ = f(x_new)\n",
    "                    f = interpolate.interp1d(time, Naval)\n",
    "                    Naval_ = f(x_new)\n",
    "                    f = interpolate.interp1d(time, LKnee)\n",
    "                    LKnee_ = f(x_new)\n",
    "                    f = interpolate.interp1d(time, LHip)\n",
    "                    LHip_ = f(x_new)\n",
    "                    f = interpolate.interp1d(time, RKnee)\n",
    "                    RKnee_ = f(x_new)\n",
    "                    f = interpolate.interp1d(time, RHip)\n",
    "                    RHip_ = f(x_new)\n",
    "\n",
    "                    RLinput = np.concatenate((np.expand_dims(Chest_, axis=1), np.expand_dims(Naval_, axis=1), np.expand_dims(LKnee_, axis=1), np.expand_dims(LHip_, axis=1), np.expand_dims(RKnee_, axis=1), np.expand_dims(RHip_, axis=1)), axis=1) \n",
    "                    min_ = np.expand_dims(np.min(RLinput,axis=0), axis=0)\n",
    "                    max_ = np.expand_dims(np.max(RLinput,axis=0), axis=0)\n",
    "                    RLinput = (RLinput - min_) / (max_ - min_)\n",
    "\n",
    "                    # OUTPUT\n",
    "                    Lcontact_output = np.zeros(len(Chest))\n",
    "                    for i in l_contact:\n",
    "                        tmp = abs(time - i)\n",
    "                        Lcontact_output[np.argmin(tmp)] = 1\n",
    "                    for idx_ in range(safe_start, safe_end - 40):\n",
    "                        count_total +=1\n",
    "                        testinput = np.expand_dims(RLinput[idx_: idx_+40], axis=0)\n",
    "                        output_predicted = np.squeeze(model.predict(testinput))\n",
    "                        answer = Lcontact_output[idx_:idx_+40]\n",
    "\n",
    "                        flag, peaks = peakDetector(output_predicted, 0.5)\n",
    "                        x = time[idx_:idx_+40]\n",
    "                        if flag:\n",
    "                            if np.count_nonzero(answer == 1) == len(peaks):\n",
    "                                count_positive += 1\n",
    "                        else:\n",
    "                            if np.count_nonzero(answer == 1) == 0:\n",
    "                                count_positive += 1\n",
    "        coverages.append(count_positive*100 / count_total)\n",
    "    print('number : {}, Converage_ave : {}, Coverage_std : {}'.format(number, np.mean(coverages), np.std(coverages)))\n",
    "\"\"\"\n",
    "for name in next(os.walk(path_dataset))[1]:\n",
    "    if name not in train_names:\n",
    "        path_person = os.path.join(path_dataset, name)\n",
    "        (root, path_zebris, path_azure) = next(os.walk(path_person))\n",
    "        print(name)\n",
    "        if '.ipynb_checkpoints' in path_zebris:\n",
    "            path_zebris.remove('.ipynb_checkpoints')\n",
    "        path_zebris = sorted(path_zebris)\n",
    "        path_azure = sorted(path_azure)\n",
    "        for idx in range(len(path_zebris)):\n",
    "            Chest, Naval, LHip, LKnee, RHip, RKnee, time, initialContactTime = getAzureData(os.path.join(path_person, path_azure[idx]))\n",
    "            firstStep, l_contact, l_off, r_contact, r_off = getZebirsData(os.path.join(path_person, path_zebris[idx]))\n",
    "\n",
    "            timeGap = initialContactTime - r_contact[0]\n",
    "            l_contact = l_contact + timeGap\n",
    "            l_off = l_off + timeGap\n",
    "            r_contact = r_contact + timeGap\n",
    "            r_off = r_off + timeGap\n",
    "            \n",
    "            while(l_off[-1] > time[-1]):\n",
    "                l_off = l_off[:-1]\n",
    "\n",
    "            while(r_off[-1] > time[-1]):\n",
    "                r_off = r_off[:-1]\n",
    "                \n",
    "                \n",
    "            tmp = abs(time - r_contact[0])\n",
    "            safe_start = np.argmin(tmp)\n",
    "\n",
    "            tmp = abs(time - max(l_off[-1], r_off[-1]))\n",
    "            safe_end = np.argmin(tmp)\n",
    "\n",
    "\n",
    "\n",
    "            fig, ax = plt.subplots(2, figsize=(18,12))\n",
    "            ax[0].plot(time, LKnee, 'r-', label = 'LKnee')\n",
    "            ax[0].plot(time, LHip, 'b-', label = 'LHip')\n",
    "            ax[0].axvline(x = initialContactTime, label='foot switch on ! at x = {}'.format(initialContactTime), c='b')\n",
    "            for i in l_contact:\n",
    "                ax[0].axvline(x=i, label='contact ! at x = {}'.format(i), c='k')\n",
    "            ax[0].axvline(x=time[safe_start], label='safe_start at x = {}'.format(i), c='g')\n",
    "            ax[0].axvline(x=time[safe_end], label='safe_end at x = {}'.format(i), c='g')\n",
    "            ax[0].axis((time[0], time[-1], 0, 90))\n",
    "            \n",
    "            # INPUT\n",
    "            x_new = np.linspace(time[0], time[-1], len(time))\n",
    "\n",
    "            f = interpolate.interp1d(time, Chest)\n",
    "            Chest_ = f(x_new)\n",
    "            f = interpolate.interp1d(time, Naval)\n",
    "            Naval_ = f(x_new)\n",
    "            f = interpolate.interp1d(time, LKnee)\n",
    "            LKnee_ = f(x_new)\n",
    "            f = interpolate.interp1d(time, LHip)\n",
    "            LHip_ = f(x_new)\n",
    "            f = interpolate.interp1d(time, RKnee)\n",
    "            RKnee_ = f(x_new)\n",
    "            f = interpolate.interp1d(time, RHip)\n",
    "            RHip_ = f(x_new)\n",
    "\n",
    "            RLinput = np.concatenate((np.expand_dims(Chest_, axis=1), np.expand_dims(Naval_, axis=1), np.expand_dims(LKnee_, axis=1), np.expand_dims(LHip_, axis=1), np.expand_dims(RKnee_, axis=1), np.expand_dims(RHip_, axis=1)), axis=1) \n",
    "            min_ = np.expand_dims(np.min(RLinput,axis=0), axis=0)\n",
    "            max_ = np.expand_dims(np.max(RLinput,axis=0), axis=0)\n",
    "            RLinput = (RLinput - min_) / (max_ - min_)\n",
    "            \n",
    "            # OUTPUT\n",
    "            Lcontact_output = np.zeros(len(Chest))\n",
    "            for i in l_contact:\n",
    "                tmp = abs(time - i)\n",
    "                Lcontact_output[np.argmin(tmp)] = 1\n",
    "                \n",
    "                \n",
    "            \n",
    "            for idx_ in range(safe_start, safe_end - 40):\n",
    "                count_total +=1\n",
    "                \n",
    "                #RLinput = np.concatenate((np.expand_dims(Chest, axis=1), np.expand_dims(Naval, axis=1), np.expand_dims(LKnee, axis=1), np.expand_dims(LHip, axis=1), np.expand_dims(RKnee, axis=1), np.expand_dims(RHip, axis=1)), axis=1) \n",
    "                testinput = np.expand_dims(RLinput[idx_: idx_+40], axis=0)\n",
    "                #min_input = np.expand_dims(np.min(testinput,axis=1), axis=0)\n",
    "                #max_input = np.expand_dims(np.max(testinput,axis=1), axis=0)\n",
    "                #testinput = (testinput - min_input) / (max_input - min_input)\n",
    "                output_predicted = np.squeeze(model.predict(testinput))\n",
    "                answer = Lcontact_output[idx_:idx_+40]\n",
    "                \n",
    "                flag, peaks = peakDetector(output_predicted, 0.5)\n",
    "                x = time[idx_:idx_+40]\n",
    "                if flag:\n",
    "                    if np.count_nonzero(answer == 1) == len(peaks):\n",
    "                        ax[1].plot(x[peaks], output_predicted[peaks], 'g.')\n",
    "                        count_positive += 1\n",
    "                    else:\n",
    "                        ax[1].plot(x[peaks], output_predicted[peaks] / 2, 'r.')\n",
    "                else:\n",
    "                    if np.count_nonzero(answer == 1) == 0:\n",
    "                        count_positive += 1\n",
    "                    else:\n",
    "                        ax[1].plot(x[peaks], output_predicted[peaks] / 3 * 2, 'k.')\n",
    "                        \n",
    "                \n",
    "\n",
    "                #\n",
    "                #ax[1].plot(x, output_predicted, 'k.')\n",
    "\n",
    "            for i in l_contact:\n",
    "                ax[1].axvline(x=i, label='contact ! at x = {}'.format(i), c='y')\n",
    "            ax[1].axvline(x=time[safe_start], label='safe_start at x = {}'.format(i), c='g')\n",
    "            ax[1].axvline(x=time[safe_end], label='safe_end at x = {}'.format(i), c='g')\n",
    "            ax[1].axis((time[0], time[-1], 0, 1.2))\n",
    "\n",
    "\n",
    "            fig.tight_layout()\n",
    "            #print('2020_11_06_testResult//' + name + path_zebris[idx] + '.png')\n",
    "            #plt.savefig('2020_11_06_testResult//' + name + path_zebris[idx] + '.png')\n",
    "            plt.close()\n",
    "            \n",
    "print('Loss : {}, Total : {}, Positive : {}, Coverage : {}%'.format(constant, count_total, count_positive, count_positive * 100 / count_total))\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
